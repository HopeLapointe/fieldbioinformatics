"""minion_nanopolish_test.py is a funcitonal test for the minion pipeline in nanopolish mode.

For each test dataset, it will make the following checks:

    * check for existence of the final consensus sequence
    * check for existence of the final VCF file (generated by artic_vcf_filter)
    * check all expected variants are reported
    * check no unexpected variants are reported
    * if there is an expected deletion, the consensus sequence will be checked for it's absence

NOTE:

    * only a basic grep is used for checking the deletion in the consensus - test will fail if deletion sequence is present multiple times (I should improve this part of the test...)

"""
import argparse
from Bio import SeqIO
import glob
import os
import pytest
import sys
import vcf

from . import pipeline


# help pytest resolve where test data is kept
TEST_DIR = os.path.dirname(os.path.abspath(__file__))


# testVariants
## the outer dict is sampleID -> dict of expected variants
## the inner dict is variant position -> a tuple of (ref, alt, type)
testVariants = {
    "CVR1":
        {
            241: ('C', 'T', "snp"),
            3037: ('C', 'T', "snp"),
            12733: ('C', 'T', "snp"),
            14408: ('C', 'T', "snp"),
            23403: ('A', 'G', "snp"),
            27752: ('C', 'T', "snp"),
            28881: ('G', 'A', "snp"),
            28882: ('G', 'A', "snp"),
            28883: ('G', 'C', "snp")
        },
    "NRW01":
        {
            1440: ('G', 'A', "snp"),
            2891: ('G', 'A', "snp"),
            4655: ('C', 'T', "snp"),
            8422: ('G', 'A', "snp"),
            22323: ('C', 'G', "snp"),
            29546: ('C', 'A', "snp")
        },
    "SP1":
        {
            241: ('C', 'T', "snp"),
            3037: ('C', 'T', "snp"),
            14408: ('C', 'T', "snp"),
            23403: ('A', 'G', "snp")
        }
}


# genCommand will create the nanopolish minion command
def genCommand(sampleID):
    return [
        "minion",
        "--read-file",
        TEST_DIR + "/../test-data/" + sampleID + "/*.fast[aq]",
        "--scheme-directory",
        TEST_DIR + "/../test-data/primer-schemes",
        "--fast5-directory",
        TEST_DIR + "/../test-data/" + sampleID + "/fast5",
        "--sequencing-summary",
        TEST_DIR + "/../test-data/" + sampleID + "/" + sampleID + "_sequencing_summary.txt",
        "nCoV-2019/V1",
        sampleID
    ]

# cleanUp will remove all files generated by the pipeline for a given sampleID
def cleanUp(sampleID):
    fileList = glob.glob("{}.*" .format(sampleID))
    for filePath in fileList:
        try:
            os.remove(filePath)
        except:
            print("Error while deleting file : ", filePath)

# checkConsensus will return 1 if a subsequence is present in a consensus file, or 0 if absent
def checkConsensus(consensusFile, subSeq):
    for record in SeqIO.parse(open(consensusFile, 'r'), 'fasta'):
        if subSeq in record.seq:
            return 1
    return 0

# test_NanopolishMinion is the unit test runner to test the minion pipeline in nanopolish mode
@pytest.mark.remote_data
def test_NanopolishMinion():

    for sampleID, expVariants in testVariants.items():

        # generate the command
        cmd = genCommand(sampleID)

        # setup and run the minion parser
        parser = pipeline.init_pipeline_parser()

        # parse the arguments
        try:
            args = parser.parse_args(cmd)
        except SystemExit:
            print("failed to parse valid command for `artic minion`")
            assert False

        # run the minion pipeline
        try:
            args.func(parser, args)
        except SystemExit:
            print("artic minion exited early with an error")
            assert False

        # check the ARTIC consensus was created
        consensusFile = "%s.consensus.fasta" % sampleID
        assert os.path.exists(consensusFile) == True, "no consensus produced for {}" .format(sampleID)

        # check the ARTIC VCF was created
        vcfFile = "%s.pass.vcf.gz" % sampleID
        assert os.path.exists(
            vcfFile) == True, "no VCF produced for {}" .format(sampleID)

        # open the VCF and check the reported variants match the expected
        for record in vcf.Reader(filename=vcfFile):
            if record.POS in expVariants:
                assert record.REF == expVariants[record.POS][0], "incorrect REF reported in VCF for {} at position {}" .format(sampleID, record.POS)
                assert str(record.ALT[0]) == expVariants[record.POS][1], "incorrect ALT reported in VCF for {} at position {}" .format(sampleID, record.POS)
                
                # if this is an expected deletion, check the consensus sequence for it's absence
                if expVariants[record.POS][2] == "del":
                    assert checkConsensus(consensusFile, record.REF) == 0, "expected deletion for {} was reported but was left in consensus" .format(sampleID)

                    # also check that the VCF record is correctly labelled as DEL
                    assert record.is_deletion, "deletion for {} not formatted correctly in VCF" .format(sampleID)

                # else, check that the VCF record is correctly labelled as SNP
                if expVariants[record.POS][2] == "snp":
                    assert record.is_snp, "snp for {} not formatted correctly in VCF" .format(sampleID)

                # remove the variant from the expected list, so we can keep track of checked variants
                del expVariants[record.POS]
            else:
                print("unexpected variant found for {}: {} at {}" .format(sampleID, str(record.ALT[0]), record.POS))
                assert False       

        # check we've confirmed all the expected variants         
        if len(expVariants) != 0:
            print("variants missed during test for {}" .format(sampleID))
            for key, val in expVariants:
                print("\t{}: {}" .format(key, val))
            assert False

        # clean up pipeline files
        cleanUp(sampleID)

        # temp break command so that we only test the first sample -- waiting on the data for the other samples
        break
